---
title: "Generation of figures and tables for the paper"
description: 
author:
  - name: Lars Relund Nielsen
    url: http://pure.au.dk/portal/en/larsrn@econ.au.dk
    affiliation: CORAL, BSS, Aarhus University
    affiliation_url: https://econ.au.dk/coral
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: true
    toc_depth: 1
editor_options: 
  chunk_output_type: console
---

```{r knitr setup, include = FALSE}
library(knitr)
library(kableExtra)
library(formatR)
# setupKnitr()
# knitr::opts_chunk$set(
#   collapse = TRUE,
#   comment = "#>",
#   fig.path = "ublb-",
#   warning=FALSE, message=FALSE, include = TRUE, 
#   out.width = "99%", fig.width = 8, fig.align = "center", fig.asp = 0.62
# )
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning=FALSE, message=FALSE, include = TRUE, 
  # cache = TRUE, autodep = TRUE,
  echo=F, #results = "hide",
  out.width = "99%", fig.width = 8, fig.align = "center", fig.asp = 0.7,
  tidy.opts = list(width.cutoff = 80), tidy = F
  # layout="l-page"   #"l-screen-inset"
)
options(knitr.kable.NA = '', knitr.table.format = "latex", width = 80)
```

```{r setup, include=FALSE}
library(gMOIP)
library(here)
library(ggsci)
library(tidyverse)
library(tikzDevice)
library(magrittr)
library(RColorBrewer)
library(wesanderson)
library(ggthemes)
library(rmarkdown)
here::i_am(path = "results/paper_tab_fig/fig_tab.Rmd")
pathOverLeaf <- "/Users/au643334/Dropbox/Apps/Overleaf/LP_relax_based_BB"
#pathOverLeaf <- here("results", "paper_tab_fig", "latex")    # change to a folder where you want the LaTeX files. The current should work
copyTabFigs <- TRUE #FALSE   # copy to Overleaf
if (isTRUE(getOption('knitr.in.progress'))) copyTabFigs <- TRUE 
```

```{r snippet function}
save_snippet <- function(name = NULL, str, path = here(pathOverLeaf, "snippets.tex"), append = T, comment = F) {
  if (comment) {
    write_lines(str, path, append = append)
  } else {
    str <- str_c("\\newcommand{\\", name, "}{", str, "}\n")
    write_lines(str, path, append = append) 
  }
}
```

```{r color scale palette used, include=FALSE}
# https://cran.r-project.org/web/packages/ggsci/vignettes/ggsci.html
library("scales")
mypal <- pal_npg("nrc", alpha = 0.8)(9)
show_col(mypal)
mypal <- pal_simpsons()(14)
show_col(mypal)
# mypal <- brewer.pal(n = 14, name = "RdYlBu")
# show_col(mypal)
mypal <- c("#74ADD1", "#A50026", "#46732EFF", "#E64B35CC")
```

```{r Define theme and color scales, include=FALSE}
theme_publish <- function() {
  library(grid)
  library(ggthemes)
  return(theme_foundation(base_size = 10) +
    theme(
      # plot.title = element_text(face = "bold", size = rel(1.2), hjust = 0.5),
      text = element_text(face = "plain"),
      # panel.background = element_rect(colour = NA),
      panel.spacing = unit(0.5, "cm"),
      plot.background = element_blank(),
      # panel.border = element_rect(colour = NA),
      axis.title = element_text(face = "plain",size = rel(1)),
      # axis.title.y = element_text(angle=90,vjust =2),
      # axis.title.x = element_text(vjust = -0.2),
      axis.text = element_text(),
      axis.line = element_line(colour="black"),
      axis.ticks = element_line(),
      panel.grid.major = element_line(colour="#f0f0f0"),
      panel.grid.minor = element_blank(),
      legend.key = element_rect(colour = NA),
      legend.position = "bottom",
      legend.direction = "horizontal",
      # legend.key.size = unit(0.2, "cm"),
      legend.key.height = unit(0.2, "cm"), 
      legend.key.width = unit(0.75, "cm"),
      # legend.margin = unit(0, "cm"),
      # legend.title = element_blank(), #element_text(face="italic"),
      # plot.margin=unit(c(10,5,5,5),"mm"),
      # strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
      # strip.text = element_text(face="bold"),
    )
  )
}

scale_alpha_solved <- scale_alpha_manual(
  values = c("solved" = 1, "reached time limit" = 0.25),
  drop = F)

scale_linetype_bound <- scale_linetype_manual(values=c("solid", "solid", "dashed", "dotted"))
```

```{r load data}
datInput <- read_csv(here("results", "paper_tab_fig", "instances.csv")) %>% 
  filter(!(class == "KP" & n > 50 & p == 3)) 

datResult <- read_csv(here("results", "convert", "csv", "resultsMain.csv")) %>%
    mutate(instance_name = str_remove(instance, "....$"))
datLastNDCpu <- read_csv(here("results", "paper_tab_fig", "stat_last_nd.csv"))
datResult <- left_join(datResult, datLastNDCpu) %>% 
  group_by(instance_name) %>% 
  filter(setequal(intersect(c("WLP", "LP"), configLB), c("WLP", "LP")))  # only instances with results for both LP and WLP

rules <- c("med2", "rand", "mofvRevisited2")  # rules to compare
datResult <- datResult %>%
  filter(configValSplit %in% rules) %>%   # remove old rules
  mutate(
    class = str_replace(instance_name, "^.*?-(.*?)_(.*)", "\\1"),
    configValSplit = case_when(   # rename rules for paper
      (class == "KP" | class == "UFLP") ~ "binary",
      configValSplit == "med2" ~ "med",
      configValSplit == "mofvRevisited2" ~ "mofv",
      TRUE ~ configValSplit
    ),
    alg_config = str_c("\\", configLB, "-\\", toupper(configValSplit))) %>% 
  group_by(instance_name) %>% 
  nest() %>% 
  mutate(winner = map(data, function(df) {df %>% arrange(cpuTotal) %>% slice(1)})) %>% 
  mutate(win = map(winner, function(df) {if_else(df$solved == 1, df$alg_config, "Unsolved")}),
         win_bound = map(winner, function(df) {if_else(df$solved == 1, toupper(df$configValSplit), "Unsolved")}),
  ) %>% 
  select(-winner) %>% 
  unnest(c(data, win, win_bound)) %>% 
  group_by(instance_name, n, class, p, configLB, configValSplit, alg_config, win, win_bound) %>% 
  summarise(across(where(is.double), mean)) %>% 
  ungroup() %>% #print() %>% 
  group_by(instance_name) %>% 
  filter(!(configLB == "WLP" & configValSplit != "binary" & length(unique(configValSplit)) < 3))   # remove instances not solved for all configs
  
  dat <- datResult %>% #filter(instance_name == "Kirlik14-ILP_p-3_n-30_m-15_ins-3") %>%
  filter(configValSplit %in% rules) %>% 
  filter(configLB == "WLP") %>% 
  group_by(instance_name) %>% 
  filter(setequal(unique(configValSplit), rules)) %>%    # only instances with results for for all rules
  mutate(configValSplit = toupper(configValSplit))

# results where at least on config solved the instance
datResultSolvedI <- datResult %>% 
  group_by(instance_name) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {any(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% 
  select(-sol) %>% 
  unnest(data) 

datResultAllSolved <- datResult %>% 
  group_by(instance_name) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% 
  select(-sol) %>% 
  unnest(data) 

datLBStat <- read_csv(here("results/paper_tab_fig/lb_set.csv"))

datOSS <- read_csv(here("results/convert/csv/resultsOSS.csv")) %>% 
  mutate(instance_name = str_remove(instance, "...$"),
         class = str_replace(instance_name, "^.*?-(.*?)_(.*)", "\\1"),
         cpuTotal = cpu,
         alg_config = "\\OSS") %>% 
  select(-cpu, -instance)

datUBStart <- read_csv(here("results/convert/csv/resultsUbWarmstart.csv")) %>% 
  mutate(
    instance_name = str_remove(instance, "....$"),
    class = str_replace(instance_name, "^.*?-(.*?)_(.*)", "\\1"),
    configValSplit = case_when(   # rename rules for paper
      (class == "KP" | class == "UFLP") ~ "binary",
      configValSplit == "med2" ~ "med",
      configValSplit == "mofvRevisited2" ~ "mofv",
      TRUE ~ configValSplit
    ),
    alg_config = str_c("\\", configLB, "-\\", toupper(configValSplit), "-UB")) 

```

## Test instances

### Instance table

Will be copied to Overleaf directly via DB:

```{r Table with problem classes}
res <- datResult 
tabInput <- nest_join(datInput, res) %>% 
  mutate(nd = map_dbl(res, function(df) {
    if (any(df$solved == 1)) 
      return(df %>% filter(solved == 1) %>% pull(YN) %>% mean())
    return(df %>% pull(YN) %>% mean())
  })) %>% 
  group_by(class, n, p) %>% 
  summarise(instances = n(), 
            range_coeff_min = min(range_coeff_min), 
            range_coeff_max = max(range_coeff_max),
            coef_nd_pct = mean(coef_nd_pct),
            const_mat_non_zeros = mean(const_mat_non_zeros),
            range_int_min = min(range_int_min),
            range_int_max = max(range_int_max),
            n_binary = mean(n_binary),
            n_integer = mean(n_integer),
            nd = mean(nd)
  )  %>%  
  group_by(class, p) %>% 
  summarise(n = str_c(n, collapse = ", "), 
            coef_nd_pct = 100*mean(coef_nd_pct),
            const_mat_non_zeros = 100*mean(const_mat_non_zeros),
            range_coeff = str_c("[", min(range_coeff_min), ",", max(range_coeff_max), "]"),
            range_int_var = str_c("[", min(range_int_min), ",", max(range_int_max), "]"),
            instances = sum(instances),
            nd = str_c(round(nd, 0), collapse = ", ")
  )  

table <- tabInput %>% 
  relocate(range_coeff, coef_nd_pct, .after = n) %>% 
  select(-range_int_var, -nd) 
table %>% kable(format = "html")
table <- table %>% 
  kable(format = "latex",
        position = "tbp",
        align = c("X","C","L","Z","Z","Z","Z"),
        escape = F,
        label = "instances",
        #table.envir = NULL,
        booktabs = T,
        digits = 0,
        linesep = "",
        col.names = c("Class", 
                      str_c("$p$", footnote_marker_alphabet(1)), 
                      str_c("$n$", footnote_marker_alphabet(2)), 
                      str_c("Range $C$", footnote_marker_alphabet(3)),
                      str_c("$\\% C$", footnote_marker_alphabet(4)),
                      str_c("$\\% A$", footnote_marker_alphabet(5)),
                      # str_c("$[\\N]$", footnote_marker_alphabet(6)),
                      str_c("\\#", footnote_marker_alphabet(6))
                      # str_c("$|\\YN|$", footnote_marker_alphabet(7))
                    ),
        caption = str_c("Instances used and average number of non-dominated points (", nrow(datInput), " instances in total).")) %>% 
  kable_styling(latex_table_env = "tabularx") %>%
  # kable_styling(latex_options = "scale_down") %>%
  footnote(alphabet = c("Number of objectives.", 
                         "Variable sizes.", 
                         "Range of the objective function coefficients $C$.",
                         "Percentage of objective coefficients not dominated by other coefficients.",
                         "Percentage of non-zeros in the constraint matrix $A$.",
                         "Number of instances."
                         # "Average number of non-dominated points for each variable size."
                        ), 
           footnote_as_chunk = F, escape = F, fixed_small_size = T) %>% 
  str_replace("centering", "tiny") %>% 
  str_replace(fixed("(\\#tab:instances)"), "\\label{tab:instances}") %>% 
  str_replace("begin\\{tabularx\\}", "begin\\{tabularx\\}\\{\\\\linewidth\\}") 

if (copyTabFigs) {
  table %>% write_file(file = here(pathOverLeaf, "tab_instances.tex"))
}
```

### Non-dominted points

Will be copied to Overleaf directly via DB:

```{r}
res <- datResult 
dat <- nest_join(datInput, res) %>% 
  mutate(nd = map_dbl(res, function(df) {
    if (any(df$solved == 1)) 
      return(df %>% filter(solved == 1) %>% pull(YN) %>% mean())
    return(df %>% pull(YN) %>% mean())
  }), 
  solved = map_chr(res, function(df) {
    if (any(df$solved == 1)) return("solved") else return("reached time limit")
  })) %>% 
  select(class,instance_name, n, nd, solved, p) 

p <- ggplot(aes(x = n, y = nd), data = dat) +
  geom_point(aes(alpha = solved, color = factor(p)), size = 0.3) + 
  geom_smooth(aes(color = factor(p)), se = F, size = 0.5) +
  facet_wrap(facets = vars(class), scales = 'free') +
  xlab("Variable size ($n$)") + ylab("$|\\mathcal{Y}_N|$") +
  labs(color = "$p$", linetype = "$p$", alpha = "") +
  theme_publish() +
  scale_alpha_solved 
p
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_nd.tex"), standAlone=F, width = 7, height = 5)
  print(p)
  dev.off()
}
```

```{r}
str <- "% Generated from R code. Don't modify if you don't know what you are doing!"
save_snippet(str = str, append = F, comment = T)
str <- str_glue("In \\autoref{{fig:nd}} the number of non-dominated points are given for each instance. We have increased the variable size for each problem class until the size becomes so large that some instances cannot be solved within the time limit. The instances which have not been solved to optimality ({res}\\%) are illustrated with transparent points. In general the number of non-dominated points grow with variable size ($n$) and number of objectives ($p$). Note though that there may be a high variation for fixed $n$ and $p$. Moreover, the variation grows with $n$ and $p$. For UFLP the number of non-dominated points grows rapidly as a function of variable size which is due to the high percentage of objective coefficients not dominated by other coefficients.",
              res = round(length(which(dat$solved != "solved"))/nrow(dat)*100))
save_snippet("snipInstancesA", str)
```







## Performance of the different algorithm configurations

Instances not solved with both LP and WLP:

```{r}
datResult %>% 
  group_by(instance_name) %>% 
  filter(!setequal(intersect(c("WLP", "LP"), configLB), c("WLP", "LP"))) %>% 
  pull(instance_name) %>% unique()
```

Groups with unsolved instances and max cpu:

```{r}
datResult %>%
  group_by(class, p) %>% 
  summarise(ctr = length(which(solved == 0)),
            maxCpu = max(cpuTotal))
```

Detailed groups with unsolved instances and max cpu:

```{r}
datResult %>%
  group_by(class, p, configLB, configValSplit) %>% 
  summarise(ctr = length(which(solved == 0)),
            cpu = mean(cpuTotal),
            minCpu = min(cpuTotal),
            maxCpu = max(cpuTotal)) %>% kable(format = "html")
```

Will be copied to Overleaf directly via DB:

```{r}
dat <- datResult %>% 
  group_by(instance_name) %>% 
  filter(setequal(intersect(c("WLP", "LP"), configLB), c("WLP", "LP"))) %>% 
  mutate(p = str_c("$p = ", p, "$"))  

p <- ggplot(dat, aes(x = n, y = cpuTotal, color = toupper(configValSplit), linetype = configLB)) +
  geom_point(size = 0.5) +
  geom_smooth(se = F, size = 0.5) +
  facet_grid(cols = vars(class), rows = vars(p), scales = "free") + 
  xlab("Variable size ($n$)") + ylab("CPU (seconds)") +
  labs(color = "", linetype = "", alpha = "") +
  theme_publish() +
  scale_alpha_solved 
p

if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_cpu.tex"), standAlone=F, width = 7, height = 4)
  print(p)
  dev.off()
}
```

Will be copied to Overleaf directly via DB:

```{r perfPlotPct}
dat <- datResult %>% 
  group_by(instance_name) %>% 
  filter(setequal(intersect(c("WLP", "LP"), configLB), c("WLP", "LP"))) %>% 
  group_by(class, p, alg_config) %>%
  arrange(cpuTotal, .by_group = T) %>%
  mutate(p = str_c("$p = ", p, "$"),
         count = row_number(), 
         total = n(), 
         pct = count/total, 
         configValSplit = toupper(configValSplit)) %>% 
  select(p, class, alg_config, cpuTotal, count, pct, total, configLB, configValSplit)
  
p <- ggplot(dat) +
  # geom_step(aes(x=tpstotal, y=count, color = nodeselVarsel, linetype = OB)) +
  geom_step(aes(y=pct, x=cpuTotal, color = configValSplit, linetype = configLB), alpha = 0.75) +
  # geom_point(aes(y=..y.., x=cpuTotal, color = configLB, linetype = configValSplit), stat="ecdf", size = 0.5) +
  facet_grid(cols = vars(class), rows = vars(p)) +
  # ggtitle(str_c("Number of instances solved within a given CPU time")) +
  labs(color = "", linetype = "") +
  # scale_color_ob + #scale_linetype_nodesel_varsel +
  xlab("CPU (seconds)") + ylab("\\%") +
  theme_publish() +
  coord_cartesian(expand = FALSE, ylim = c(0, NA), xlim = c(-10, 3595)) 
p
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_pref_pct.tex"), standAlone=F, width = 7, height = 4)
  print(p)
  dev.off()
}
```


```{r}
dat <- datResultSolvedI %>% 
  mutate(CompProblem = (class %in% c("KP", "UFLP"))) %>% 
  group_by(alg_config, CompProblem) %>% 
  summarize(cpu = mean(cpuTotal), .groups = "drop") %>% 
  group_by(CompProblem) %>% 
  arrange(cpu, .by_group = T) %>% 
  mutate(pct = round(100*(cpu/min(cpu) - 1))) %>% print()
datIP <- dat %>% filter(!CompProblem)
datComp <- dat %>% filter(CompProblem)

dat1 <- datResultSolvedI %>% 
  group_by(instance_name, configLB) %>% 
  arrange(cpuTotal, .by_group = T) %>% 
  slice_head(n=1) %>% 
  group_by(configLB) %>% 
  summarize(cpu = mean(cpuTotal), .groups = "drop") %>% 
  arrange(cpu) %>% 
  mutate(pct = round(100*(cpu/min(cpu) - 1))) %>% print()

datResultSolvedI %>% 
  group_by(instance_name, configLB) %>% 
  arrange(cpuTotal, .by_group = T) %>% 
  slice_head(n=1) %>%
  filter(!str_detect(win, "WLP")) %>% 
  group_by(instance_name) %>% 
  summarise(diff = max(cpuTotal)- min(cpuTotal)) %>% print()

datResultSolvedI %>% 
  group_by(instance_name, win) %>% 
  nest() %>% 
  filter(!str_detect(win, "WLP")) %>% pull(instance_name) 
  
dat2 <- datResultSolvedI %>% 
  group_by(instance_name, win) %>% 
  nest() %>% 
  mutate(win_wlp = str_detect(win, "WLP")) %>% 
  group_by(win_wlp) %>% 
  summarize(ctr = n()) %>% print()

str <- str_glue("First, we rank the configurations with respect to the average CPU time for all solved instances. The sequence from best to worst for the integer problems with non-binary variables (ILP and PPP) becomes {res1}, where the increase in percentages compared to the best configuration is given in parentheses. For the combinatorial problems (KP and UFLP), WLP performed on average {res2}\\% faster compared to \\LP. 
                
A plot of the CPU time for each instance is given in \\autoref{{fig:cpu}}. Note the variation in CPU time for the 10 instances given each class and variable size. Warm-starting the computation (\\WLP) in general performs better than \\LP. On average \\WLP (using the best variable selection configuration) performed {res3}\\% faster compared to \\LP. This can also be seen in \\autoref{{fig:performanceProfiles}} illustrating the number of solved instances given a  CPU time limit. We have increased the variable size for each problem class until the size becomes so large that some instances cannot be solved within the time limit. That is, the number of instances solved before the time limit is below 100\\%.

In a few instances \\LP performed best (fastest in {res4}\\% of the instances). We will have a closer look at the reason for this in \\autoref{{sec:resDetails}}",
                res1 = knitr::combine_words(str_c(datIP$alg_config, " (", datIP$pct, "\\%)")),
                res2 = datComp$pct[2],
                res3 = dat1$pct[2],
                res4 = round(100 * (dat2 %>% filter(!win_wlp) %>% pull(ctr)/sum(dat2$ctr))))
save_snippet("snipAlgConfigA", str)
```



```{r, eval=FALSE}
str <- ""

dat <- datResultSolvedI %>%
  group_by(instance_name, configLB, class) %>%
  summarise(cpu = mean(cpuTotal, na.rm = T)) %>% 
  pivot_wider(names_from = configLB, values_from = cpu) %>% 
  mutate(cpu_pct = 1- WLP/LP) %>% 
  group_by(class) %>% 
  summarise(cpu_pct = round(100 * mean(cpu_pct))) %>% print()
str <- str_c(str, str_glue(
  "If we compare problem classes \\WLP performs well for all classes with an average CPU time reduction of {combine_words(res)} for {combine_words(dat$class)}, respectively.",
  res = str_c(dat$cpu_pct, "\\%")
), sep = " ")

dat <- datResultSolvedI %>% 
  group_by(instance_name, win, class) %>% 
  nest() %>% 
  mutate(win_wlp = str_detect(win, "WLP")) %>% 
  filter(!win_wlp) %>% 
  unnest(data) %>% 
  filter(win == alg_config) %>% 
  group_by(class) %>% 
  summarise(ctr = n(), cpu = round(mean(cpuTotal))) 
str <- str_c(str, str_glue(
  "In a few instances \\LP performs best. This happens for {dat %>% filter(class == 'ILP') %>% pull(ctr)} instances in ILP with an average CPU time of {dat %>% filter(class == 'ILP') %>% pull(cpu)} seconds. We will have a closer look at reason for this in \\autoref{{sec:resDetails}}."
), sep = " ")

save_snippet("snipAlgConfigB", str)
```



## Variable selection - Rules for choosing the bound

```{r}
rules <- c("med", "rand", "mofv")  # rules to compare
dat <- datResultSolvedI %>% #filter(instance_name == "Kirlik14-ILP_p-3_n-30_m-15_ins-3") %>%
  filter(configValSplit %in% rules) %>% 
  filter(configLB == "WLP") %>% 
  group_by(instance_name) %>% 
  filter(setequal(unique(configValSplit), rules))   # only instances with results for for all rules
```

Group with cpu and nodes:

```{r}
dat %>%
  group_by(class, configValSplit) %>%
  summarize(instances = n(), cpu = mean(cpuTotal), nodes = mean(nbNodes)) %>%
  arrange(nodes)
```

Group with cpu and nodes:

```{r}
dat %>%
  group_by(configValSplit) %>%
  summarize(instances = n(), cpu = mean(cpuTotal), nodes = mean(nbNodes)) %>%
  arrange(nodes)
```


```{r}
dat <- dat %>% ungroup() %>% 
  group_by(instance_name) %>% 
  arrange(cpuTotal, .by_group = T) %>% 
  slice_head(n = 2) %>%  
  mutate(diff = cpuTotal-min(cpuTotal),
         pct = round(100*(cpuTotal/min(cpuTotal) - 1))) %>% 
  select(instance_name, diff, pct, cpuTotal, configValSplit, win_bound, class) %>% 
  arrange(cpuTotal, .by_group = T) %>% #print %>% 
  group_by(win_bound) %>%
  summarize(ctr = n(), diff = mean(diff), pct = mean(pct)) %>%
  # group_by(configValSplit) %>% 
  mutate(ctr_pct = round(100 * ctr/sum(ctr))) %>% 
  arrange(desc(ctr_pct), .by_group = T) %>% print() %>% 
  ungroup() %>% 
  slice_head(n = 1) 
str <- str_glue(
  "We are here interested in determining whether one rule for finding the bound ({res1}) is consistently better than the other when considering non-binary integer problems. Since the effect on the branching tree of using \\LP vs \\WLP is negligible, we will consider the \\WLP configuration here. By considering the performance profiles in \\autoref{{fig:performanceProfiles}} we see that there is no clear winner among {res1}. 
  
The {res2}-configuration performed best in {dat$ctr_pct}\\% of the instances. If we compare with the second best rule for each instance, the CPU time on average increased with {res3} seconds (a {res4}\\% increase).",
  res1 = knitr::combine_words(toupper(str_c("\\", rules))),
  res2 = str_c("\\", dat$win_bound),
  res3 = round(dat$diff),
  res4 = round(dat$pct)
  )
save_snippet("snipBoundA", str)
```



### Bound rule figure
  
Will be copied to Overleaf directly via DB:

```{r CPU plot}
dat <- datResultAllSolved %>% #filter(instance_name == "Kirlik14-ILP_p-3_n-30_m-15_ins-3") %>%
  filter(configValSplit %in% rules) %>% 
  filter(configLB == "WLP") %>% 
  group_by(instance_name) %>% 
  filter(setequal(unique(configValSplit), rules)) %>%    # only instances with results for for all rules
  mutate(configValSplit = toupper(configValSplit)) %>% 
  mutate(p = str_c("$p = ", p, "$"))  
         
p <- ggplot(aes(x = n, y = nbNodes, color = configValSplit), data = dat) +
  # geom_point(size = 0.5) +
  geom_smooth(se = F, size = 0.5) +
  facet_grid(rows = vars(class), cols= vars(p), scales = "free") +
  # ggtitle(str_c("Number of instances solved within a given CPU time")) +
  labs(color = "", linetype = "") +
  # scale_color_ob + #scale_linetype_nodesel_varsel +
  xlab("Number of variables") + ylab("Nodes in the branching tree") +
  theme_publish() 
  # coord_cartesian(expand = FALSE, ylim = c(0, NA), xlim = c(-10, NA))
p
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_bound.tex"), standAlone=F, width = 7, height = 3)
  print(p)
  dev.off()
}
```


```{r bound table, eval=FALSE}
dat1 <- datResultSolvedI %>% #filter(instance_name == "Kirlik14-ILP_p-3_n-30_m-15_ins-10") %>% view()
  filter(class != "UFLP") %>%   # remove binary
  group_by(instance, win) %>%
  mutate(win_lb = if_else(str_detect(win, "WLP"), "WLP", "LP"),
         win_bound = case_when(
           str_detect(win, "MED") ~ "med",
           str_detect(win, "MOFV") ~ "mofv",
           str_detect(win, "RAND") ~ "rand",
           TRUE ~ "error"
         )) %>% 
  filter(configLB == win_lb) %>% # only consider the win LB config
  group_by(instance_name) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  select(instance_name, configValSplit, cpuTotal, class, p) %>%
  group_by(instance_name) %>%
  pivot_wider(names_from = configValSplit, values_from = c(cpuTotal), values_fill = NA, values_fn = {mean}) %>%
  group_by(class, p) %>%
  summarise(avgSpeedup = mean(med/mofv)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgSpeedup)

dat2 <- datResultSolvedI %>% 
  filter(class != "UFLP") %>%   # remove binary
  group_by(instance, win) %>%
  mutate(win_lb = if_else(str_detect(win, "WLP"), "WLP", "LP"),
         win_bound = if_else(str_detect(win, "MED"), "med", "mofv")) %>% 
  filter(configLB == win_lb) %>% # only consider the win LB config
  group_by(instance_name) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  select(instance_name, configValSplit, nbNodes, class, p) %>%
  group_by(instance_name) %>%
  pivot_wider(names_from = configValSplit, values_from = c(nbNodes)) %>% #filter(mofv > med)
  group_by(class, p) %>%
  summarise(avgSpeedup = mean(med/mofv)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = avgSpeedup)

dat <- bind_cols(dat1,dat2 %>% select(-class)) %>% 
  mutate(across(where(is.numeric), ~format(round(.x, 2), nsmall = 2)))

table <- dat %>% 
  kable(format = "latex",
        position = "tbp",
        align = c("X","Y","Y","Y","Y","Y","Y"),
        escape = F,
        label = "factorBound",
        #table.envir = NULL,
        booktabs = T,
        digits = 0,
        linesep = "",
        col.names = c("Class",
                      str_c("$p=3$"), str_c("$p=4$"), str_c("$p=5$"),
                      str_c("$p=3$"), str_c("$p=4$"), str_c("$p=5$")
                    ),
        caption = "Speed-up factor of using \\MOFV instead of \\MED for each problem class and number of objectives.") %>% 
  kable_styling(latex_table_env = "tabularx") %>%
  add_header_above(c(" " = 1, "Cpu" = 3, "Branching tree size" = 3))%>% 
  # kable_styling(latex_options = "scale_down") %>% 
  str_replace("begin\\{tabularx\\}", "begin\\{tabularx\\}\\{\\\\linewidth\\}") %>% 
  str_replace("centering", "footnotesize") %>% 
  str_replace(fixed("(\\#tab:factorBound)"), "\\label{tab:factorBound}")
table

if (copyTabFigs) {
  table %>% write_file(file = here(pathOverLeaf, "tab_bound.tex"))
}
```


## Detailed performance of different algorithm parts

Will be copied to Overleaf directly via DB:

```{r factor lp/wlp table}
dat <- datResult %>% 
  filter(configValSplit == "mofv" | configValSplit == "binary") %>% 
  group_by(instance_name) %>%
  filter(setequal(c("WLP", "LP"), configLB)) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  select(instance_name, configLB, cpuTotal, nbLpSolved, class, p) %>%
  group_by(instance_name) %>%
  pivot_wider(names_from = configLB, values_from = c(cpuTotal, nbLpSolved)) %>%
  ungroup() %>%
  group_by(class, p) %>%
  summarise(avgSpeedup = mean(cpuTotal_LP/cpuTotal_WLP), avgLP = mean(nbLpSolved_LP/nbLpSolved_WLP)) %>%
  ungroup() %>%
  pivot_wider(names_from = p, values_from = c(avgSpeedup, avgLP)) %>% print

dat %>% kable(format = "html")
table <- dat %>% 
  kable(format = "latex",
        position = "tbp",
        align = c("X","Y","Y","Y","Y","Y","Y"),
        escape = F,
        label = "factorLB",
        #table.envir = NULL,
        booktabs = T,
        digits = 2,
        linesep = "",
        col.names = c("Class",
                      str_c("$p=3$"), str_c("$p=4$"), str_c("$p=5$"),
                      str_c("$p=3$"), str_c("$p=4$"), str_c("$p=5$")
                    ),
        caption = "Speed-up factor using \\WLP instead of \\LP for each problem class and number of objectives. The rule for choosing the bound is \\MOFV.") %>% 
  kable_styling(latex_table_env = "tabularx") %>%
  add_header_above(c(" " = 1, "Cpu" = 3, "LPs solved" = 3))%>% 
  # kable_styling(latex_options = "scale_down") %>% 
  str_replace("begin\\{tabularx\\}", "begin\\{tabularx\\}\\{\\\\linewidth\\}") %>% 
  str_replace("centering", "footnotesize") %>% 
  str_replace(fixed("(\\#tab:factorLB)"), "\\label{tab:factorLB}")

if (copyTabFigs) {
  table %>% write_file(file = here(pathOverLeaf, "tab_factor_lb.tex"))
}
```

```{r detailed text}
dat <- datResult %>% 
  filter(configValSplit == "mofv" | configValSplit == "binary") %>% 
  group_by(instance_name) %>%
  filter(setequal(c("WLP", "LP"), configLB)) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  select(instance_name, configLB, cpuTotal, nbLpSolved, class, p, n) %>%
  group_by(instance_name) %>%
  pivot_wider(names_from = configLB, values_from = c(cpuTotal, nbLpSolved)) %>%
  ungroup() %>%
  group_by(class, p, n) %>%
  summarise(avgSpeedup = mean(cpuTotal_LP/cpuTotal_WLP), avgLP = mean(nbLpSolved_LP/nbLpSolved_WLP)) 

ggplot(dat, aes(x = n, y = avgSpeedup, color = factor(p))) + 
  geom_point() +
  geom_line() +
  facet_grid(rows = vars(class))

dat <- datResult %>% 
  filter(configValSplit == "mofv" | configValSplit == "binary") %>% 
  group_by(instance_name) %>%
  filter(setequal(c("WLP", "LP"), configLB)) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  select(instance_name, configLB, cpuTotal, nbLpSolved, class, p, n) %>%
  group_by(instance_name) %>%
  pivot_wider(names_from = configLB, values_from = c(cpuTotal, nbLpSolved)) %>%
  ungroup() %>%
  group_by(class, p) %>%
  summarise(avgSpeedup = mean(cpuTotal_LP/cpuTotal_WLP), avgLP = mean(nbLpSolved_LP/nbLpSolved_WLP)) 


dat2 <- datResult %>% 
  filter(configValSplit == "mofv" | configValSplit == "binary") %>% 
  group_by(instance_name) %>%
  filter(setequal(c("WLP", "LP"), configLB)) %>% 
  nest() %>% 
  mutate(sol = map(data, function(df) {all(df$solved == 1)})) %>% 
  unnest(sol) %>% 
  filter(sol) %>% # remove instances with unsolved configs
  select(-sol) %>% 
  unnest(data) %>% 
  mutate(
    pctLB = 100 * cpuLbComputation / cpuTotal ,
    pctUB = 100 * cpuUbUpdate / cpuTotal ,
    pctDomiTest = 100 * cpuDominanceTest / cpuTotal ,
    pctNodeSel = 100 * cpuNodeSel / cpuTotal ,
    pctVarSel = 100 * cpuVarSel / cpuTotal ,
    pctOther = 100 - pctLB - pctUB - pctDomiTest - pctNodeSel - pctVarSel
  ) %>%
  group_by(p, configLB, class) %>%
  summarise(
    `Calculation of LB` = mean(pctLB) ,
    `Updating UB` = mean(pctUB) ,
    `Pruning nodes` = mean(pctDomiTest) ,
    Other = mean(pctOther) + mean(pctNodeSel) + mean(pctVarSel)
  ) %>% print()
str <- str_glue("In this section, we take a closer look at different parts of \\autoref{{alg:BB}}. Different speed-up factors by using \\WLP instead of \\LP are given in \\autoref{{tab:factorLB}}. The factor is obtained by dividing the \\LP value with the \\WLP value. Only instances with both configurations solved are recorded. \\WLP are on average {res1} times faster than \\LP with significant differences among the problem classes, \\eg for problem class UFLP, \\WLP is on average {res2} times faster while for class ILP the speed-up is {res3}.
                
Most of the CPU time ({res4a}\\% for \\LP and {res4b}\\% for \\WLP) is used on calculating the lower bound set (\\autoref{{alg:benson}}) and the speed-up is mainly due to a reduction in the number of times the linear programming solver has to be called on \\autoref{{l:checkV}} in \\autoref{{alg:benson}}. This can be seen in \\autoref{{tab:factorLB}}. For example, for UFLP \\WLP is {res2} times faster and solves {res5} times less linear programs on average than \\LP. However, when using \\WLP the initial outer approximation has to be copied from the father node into the child node and managing the polyhedron is harder since we have to check for redundant half-spaces in \\autoref{{alg:updateP}} (lines \\ref{{l:sRemoveH}}-\\ref{{l:eRemoveH}}). As a result we have a smaller reduction in CPU times than the reduction in number of LPs solved.",
  res1 = round(mean(dat$avgSpeedup), 2),
  res2 = round(dat %>% filter(class == "UFLP") %>% pull(avgSpeedup) %>% mean(), 2),
  res3 = round(dat %>% filter(class == "ILP") %>% pull(avgSpeedup) %>% mean(), 2),
  res4a = round(dat2 %>% filter(configLB == "LP") %>% pull(`Calculation of LB`) %>% mean),
  res4b = round(dat2 %>% filter(configLB == "WLP") %>% pull(`Calculation of LB`) %>% mean),
  res5 = round(dat %>% filter(class == "UFLP") %>% pull(avgLP) %>% mean(), 2)
  )
save_snippet("snipDetailsA", str)
```

```{r parts BB fig, eval=FALSE}
p <- datResult %>%
  filter(configValSplit == "mofv" | class == "UFLP", solved == 1) %>%
  mutate(
    pctLB = 100 * cpuLbComputation / cpuTotal ,
    pctUB = 100 * cpuUbUpdate / cpuTotal ,
    pctDomiTest = 100 * cpuDominanceTest / cpuTotal ,
    pctNodeSel = 100 * cpuNodeSel / cpuTotal ,
    pctVarSel = 100 * cpuVarSel / cpuTotal ,
    pctOther = 100 - pctLB - pctUB - pctDomiTest - pctNodeSel - pctVarSel
  ) %>%
  group_by(p, configLB, class) %>%
  summarise(
    `Calculation of LB` = mean(pctLB) ,
    `Updating UB` = mean(pctUB) ,
    `Pruning nodes` = mean(pctDomiTest) ,
    Other = mean(pctOther) + mean(pctNodeSel) + mean(pctVarSel)
  ) %>%
  pivot_longer(!c(class, p, configLB) , names_to = "part" , values_to = "pctCpu") %>%
  ggplot(aes(
    x = factor(configLB),
    y = pctCpu,
    fill = part
  )) +
  geom_col(color = "black") +
  geom_text(
    aes(label = round(pctCpu, 1)),
    colour = "white",
    size = 2.5,
    position = position_stack(vjust = .5)
  ) +
  facet_grid(
    rows = vars(class) ,
    cols = vars(p),
    margins = F,
    # scales = "free"
  ) +
  labs(color = "", fill = "") +
  ylab("percent of total CPU time") + xlab("") +
  theme_publish() 
p

if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_part_bb.tex"), standAlone=F, width = 7, height = 6)
  print(p)
  dev.off()
}
```

Will be copied to Overleaf directly via DB:

```{r, eval=FALSE}
dat <- datResult %>%
  filter(configValSplit == "mofv" | class == "UFLP", solved == 1) %>%
  group_by(p, class, configLB) %>% 
  summarise(poly = mean(cpuUpdatePolyhedron)) %>% print() %>% 
  group_by(configLB) %>% 
  summarise(poly = mean(poly)) %>% print
  
  
  
  mutate(cpuLbComputation = cpuLbComputation - cpuInitialization) %>% 
  
  mutate(
    pctCplex = 100 * cpuCplex / cpuLbComputation ,
    pctUpdatePolyhedron = 100 * cpuUpdatePolyhedron / cpuLbComputation ,
    pctOther = 100 - pctCplex - pctUpdatePolyhedron
  ) %>%
  group_by(p, class, configLB) %>%
  summarise(
    `Solve LPs` = mean(pctCplex) ,
    `Update polyhedron` = mean(pctUpdatePolyhedron) ,
    Other = mean(pctOther)
  ) %>%
  pivot_longer(!c(p, class, configLB) , names_to = "part" , values_to = "pctCpu") 

dat %>% group_by(p, class, configLB) %>% summarise(pct = sum(pctCpu))
dat %>% group_by(p, class, configLB) %>% summarise()
```


```{r parts benson fig}
datResult %>%
  filter(configValSplit %in% c("mofv", "binary"), solved == 1) %>%
  group_by(p, class, configLB) %>% 
  summarise(across(starts_with("cpu"), mean)) 

dat <- datResult %>%
  filter(configValSplit %in% c("mofv", "binary"), solved == 1) %>%
  mutate(
    pctCplex = 100 * cpuCplex / cpuLbComputation ,
    pctUpdatePolyhedron = 100 * cpuUpdatePolyhedron / cpuLbComputation ,
    pctInitialization = 100 * (cpuInitialization + cpuLbCopy) / cpuLbComputation,
    pctOther = 100 - pctCplex - pctUpdatePolyhedron - pctInitialization
  ) %>% 
  group_by(p, class, configLB) %>%
  summarise(
    `Solve LPs` = mean(pctCplex) ,
    `Update polyhedron` = mean(pctUpdatePolyhedron) ,
    `Initialization` = mean(pctInitialization) ,
    Other = mean(pctOther)
  ) %>%
  pivot_longer(!c(p, class, configLB) , names_to = "part" , values_to = "pctCpu") 
p <- dat %>% ggplot(aes(
    x = factor(configLB),
    y = pctCpu,
    fill = part
  )) +
  geom_col(color = "black") +
  geom_text(
    aes(label = round(pctCpu, 1)),
    colour = "white",
    size = 2.5,
    position = position_stack(vjust = .5)
  ) +
  facet_grid(
    rows = vars(class) ,
    cols = vars(p),
    margins = F,
    # scales = "free"
  ) +
  labs(color = "", fill = "") +
  ylab("percent of total CPU time") + xlab("") +
  theme_publish() 
p

if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_part_benson.tex"), standAlone=F, width = 7, height = 6)
  print(p)
  dev.off()
}
```


## Polyhedral properties of the lower bound set during the algorithm

```{r}
# dat <- datLBStat %>% 
#   # filter(configLB == "WLP") %>% 
#   transmute(instance_name, class, configLB, configValSplit, depth, p, avgFacetsNoRay, avgFacet,
#             # facetsLB = avgFacetsNoRay, 
#             facetsWRays = avgFacet - avgFacetsNoRay, 
#             avgVtxNoRay,
#             verticesF = avgVtxNoRay/avgFacetsNoRay) %>%  view

dat <- datLBStat %>% 
  # filter(configLB == "WLP") %>% 
  group_by(class, configLB, configValSplit, depth, p, n) %>% 
  summarise(avgFacetsLB = mean(avgFacetsNoRay), 
            avgFacetsWRays = mean(avgFacet - avgFacetsNoRay), 
            avgVertices = mean(avgVtxNoRay),
            avgVerticesFacetsLB = mean(if_else(avgFacetsNoRay == 0, 0, avgVtxNoRay/avgFacetsNoRay)),
            pct = mean(avgFeasVtx/avgVertex)  # proportion of old vertices and rays in the polyhederon
        ) %>% 
  mutate(p = str_c("$p = ", p, "$"))  
  
# dat %>%  
#   select(-avgVerticesFacetsLB, -pct) %>% 
#   pivot_longer(cols = starts_with("avg")) %>% 
#   ggplot(aes(x = depth, y = value, color = name, linetype = configLB)) +
#   geom_line() +
#   facet_grid(rows = vars(class, configValSplit), cols = vars(p), scales = "free")
#   # facet_wrap(vars(class, configValSplit, p), scales = "free")

# dat %>%  
#   select(class, configLB, configValSplit, depth, p, avgVerticesFacetsLB) %>% 
#   pivot_longer(cols = starts_with("avg")) %>% 
#   ggplot(aes(x = depth, y = value, color = name, linetype = configLB)) +
#   geom_line() +
#   facet_grid(rows = vars(class, configValSplit), cols = vars(p), scales = "free")

p1 <- dat %>%  
  filter(configValSplit == "MOFVREVISITED2", configLB == "WLP") %>% 
  select(-avgVerticesFacetsLB, -pct) %>% 
  pivot_longer(cols = starts_with("avg")) %>% 
  mutate(name = case_when(
    name == "avgFacetsLB" ~ "Facets in $\\mathcal{Y}_{N}^{LP}(\\eta)$",
    name == "avgFacetsWRays" ~ "Facets with rays in $\\mathcal{P}_{\\geqq}^{LP}(\\eta)$",
    name == "avgVertices"~ "Vertices in $\\mathcal{Y}_{N}^{LP}(\\eta)$",
    TRUE ~ "error")) %>% 
  ggplot(aes(x = depth, y = value, linetype = p, color = factor(n))) +
  geom_line() +
  #geom_smooth(se = F) +
  facet_wrap(vars(name, class), ncol = 4, scales = "free") +
  labs(color = "$n$", linetype = "") +
  guides(color = guide_legend(nrow = 2)) +
  # scale_color_ob + #scale_linetype_nodesel_varsel +
  xlab("branching tree depth") + ylab("") +
  scale_color_manual(values = wes_palette(14, name = "Royal1", type = "continuous")) +
  # scale_color_manual(values = setNames(scale_colour_discrete()$palette(n=3), c("avgFacetsLB", "avgFacetsWRays", "avgVertices")), 
  #                    labels = c("Facets in $\\mathcal{Y}_{N}^{LP}(\\eta)$", "Facets with rays in $\\mathcal{P}_{\\geqq}^{LP}(\\eta)$", "Vertices in $\\mathcal{Y}_{N}^{LP}(\\eta)$")) +
  theme_publish() 
p1

# p2 <- dat %>%  
#   filter(configValSplit == "MOFVREVISITED2", configLB == "WLP") %>% 
#   select(-avgVerticesFacetsLB) %>% 
#   pivot_longer(cols = starts_with("avg")) %>% 
#   mutate(name = case_when(
#     name == "avgFacetsLB" ~ "Facets in $\\mathcal{Y}_{N}^{LP}(\\eta)$",
#     name == "avgFacetsWRays" ~ "Facets with rays in $\\mathcal{P}_{\\geqq}^{LP}(\\eta)$", 
#     name == "avgVertices" ~ "Vertices in $\\mathcal{Y}_{N}^{LP}(\\eta)$",
#     TRUE ~ "error"
#   )) %>% 
#   ggplot(aes(x = depth, y = value, color = class)) +
#   geom_line() +
#   facet_grid(cols = vars(name), rows = vars(p), scales = "free") +
#   labs(color = "", linetype = "") +
#   # scale_color_ob + #scale_linetype_nodesel_varsel +
#   xlab("branching tree depth") + ylab("") +
#   #scale_color_manual(values = setNames(scale_colour_discrete()$palette(n=4), c("avgFacetsLB", "avgFacetsWRays", "avgVertices")), 
#                      #labels = c("Facets in $\\mathcal{Y}_{N}^{LP}(\\eta)$", "Facets with rays in $\\mathcal{P}_{\\geqq}^{LP}(\\eta)$", "Vertices in $\\mathcal{Y}_{N}^{LP}(\\eta)$")) +
#   theme_publish() 
# p2


options(tikzMetricPackages = c(
  "\\usepackage[utf8]{inputenc}", 
  "\\usepackage[T1]{fontenc}", 
  "\\usetikzlibrary{calc}",
  "\\usepackage{amssymb}"))
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_lb.tex"), standAlone=F, width = 8, height = 6)
  print(p1)
  dev.off()
}

# p2 <- dat %>% ungroup() %>% 
#   filter(configValSplit == "MOFVREVISITED2", configLB == "WLP") %>% 
#   select(class, depth, p, pct) %>% 
#   ggplot(aes(x = depth, y = pct, color = factor(p))) +
#   geom_line() +
#   # geom_point() +
#   facet_grid(rows = vars(class)) +
#   theme_publish() 
# p2
# if (copyTabFigs) {
#   tikz(file = here(pathOverLeaf, "fig_lb_pct.tex"), standAlone=F, width = 7, height = 4)
#   print(p2)
#   dev.off()
# }
# 
# dat %>%  
#   filter(configValSplit == "MOFVREVISITED2", configLB == "WLP") %>% 
#   select(class, configLB, configValSplit, depth, p, avgVerticesFacetsLB) %>% 
#   pivot_longer(cols = starts_with("avg")) %>% 
#   ggplot(aes(x = depth, y = value, color = name, linetype = configLB)) +
#   geom_line() +
#   facet_grid(rows = vars(class), cols = vars(p), scales = "free")
```


## Pct of CPU used to find the ND set

```{r}
datResult %>% 
  filter(solved == 1, configLB == "WLP") %>% 
    mutate(pct = mean(lastNDCpu/cpuTotal)) %>% 
  # group_by(class, p, n, configLB, configValSplit) %>% 
  # summarize(pct = mean(lastNDCpu/cpuTotal)) %>% 
  ggplot(aes(x = n, y = pct, color = configValSplit)) + 
  # geom_jitter() +
  geom_smooth(se = F, size = 0.4) +
  facet_grid(rows = vars(class), cols = vars(p), scales = "free")
```


## Proving optimality

```{r}
dat <- datResultSolvedI %>% 
  filter(configValSplit %in% c("mofv", "binary"), configLB == "WLP") %>% 
  bind_rows(datUBStart) %>% 
  mutate(alg_config = if_else(str_detect(alg_config, "UB"), "\\texttt{\\small WLP-UB}", "\\texttt{\\small WLP}")) %>% 
  mutate(p = str_c("$p = ", p, "$")) %>% 
  group_by(instance_name) %>% 
  filter(setequal(alg_config, c("\\texttt{\\small WLP-UB}", "\\texttt{\\small WLP}")))   # only instances with results for for all alg
p <- ggplot(dat, aes(x = n, y = cpuTotal, color = alg_config)) +
  geom_point(size = 0.5) +
  geom_smooth(se = F, size = 0.75) +
  facet_grid(cols = vars(class), rows = vars(p), scales = "free") + 
  xlab("Variable size ($n$)") + ylab("CPU (seconds)") +
  labs(color = "", linetype = "", alpha = "") +
  theme_publish() 
p
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_ub_leaf.tex"), standAlone=F, width = 8, height = 4)
  print(p)
  dev.off()
}

p <- dat %>% 
  filter(solved == 1) %>%
  filter(setequal(alg_config, c("\\texttt{\\small WLP-UB}", "\\texttt{\\small WLP}"))) %>% 
  mutate(
    nbLeaf = nbFathomedInfeas + nbFathomedOptimality + nbFathomedDominance,
    pctFathomedInfeas = nbFathomedInfeas/nbLeaf,
    pctFathomedOptimality = nbFathomedOptimality/nbLeaf,
    pctFathomedDominance = nbFathomedDominance/nbLeaf
  ) %>%
  group_by(p, class, alg_config) %>%
  summarise(across(starts_with("pct"), mean)) %>% 
  rename(infeasibility = pctFathomedInfeas, 
         optimality = pctFathomedOptimality, 
         dominance = pctFathomedDominance) %>% 
  pivot_longer(!c(class, p, alg_config) , names_to = "part" , values_to = "pctCpu") %>%
  mutate(pctCpu = 100 * pctCpu,
         class = if_else(str_detect(alg_config, "UB"), str_c(class, "-", "UB"), class)) %>% 
  ggplot(aes(
    x = factor(class),
    y = pctCpu,
    fill = part
  )) +
  geom_col(color = "black") +
  geom_text(
    aes(label = round(pctCpu, 1)),
    colour = "white",
    size = 2.5,
    position = position_stack(vjust = .5)
  ) +
  facet_grid(
    cols = vars(p),
    # scales = "free"
  ) +
  labs(color = "", fill = "") +
  ylab("percent of leaf nodes") + xlab("") +
  theme_publish() 
p
```


```{r}
dat <- datResultSolvedI %>% 
  filter(configValSplit %in% c("mofv", "binary"), configLB == "WLP", solved == 1) %>% 
  bind_rows(datUBStart) %>% 
  mutate(alg_config = if_else(str_detect(alg_config, "UB"), "WLPUB", "WLP")) %>% 
  mutate(p = str_c("$p = ", p, "$"),) %>% 
  group_by(instance_name) %>% 
  filter(n() == 2) %>% 
  select(instance_name, class, p, alg_config, cpuTotal, nbNodes) %>% 
  pivot_wider(names_from = alg_config, values_from = c(cpuTotal, nbNodes)) %>% 
  ungroup() %>% 
  mutate(fct = cpuTotal_WLP/cpuTotal_WLPUB, 
         pct = 100*(cpuTotal_WLP-cpuTotal_WLPUB)/cpuTotal_WLP,
         pctInc = 100*(cpuTotal_WLP-cpuTotal_WLPUB)/cpuTotal_WLPUB,
         pctNodes = 100*(nbNodes_WLP-nbNodes_WLPUB)/nbNodes_WLPUB) %>% 
  group_by(p, class) %>% 
  summarise(across(where(is.double), mean)) 

str <- str_glue("As can be seen from \\autoref{{fig:ub-leaf}} the reduction in CPU time is significant. On average over all the instances the speed-up factor is {res1} meaning that on average, not providing an optimal solution at the root node, makes the cpu time increase with {res2}\\%.
                
As there is no significant computation time involved in generating solutions in our branch-and-bound algorithm (feasible solutions are simply harvested from integer feasible vertices of the lower bound sets), the speed-up must come from the increased pruning potential. The number of nodes in the branching tree on average increase with {res3}\\% for \\WLP. Note also, that in the \\WLPUB configuration, the algorithm still check whether each integer feasible vertex of the lower bound sets found should enter the upper bound set, which underlines the fact that the reduction in computation time comes from the increased pruning potential.",
  res1 = round(mean(dat$fct), 2),
  res2 = round(mean(dat$pctInc)),
  res3 = round(mean(dat$pctNodes))
) 
save_snippet("snipOptimalityA", str)
```



## Performance of the multi-objective B\&B algorithm compared to an objective space search algorithm

```{r}
dat <- datResult %>% 
  filter(configValSplit %in% c("mofv", "binary"), configLB == "WLP") %>% 
  bind_rows(datOSS) %>% 
  group_by(instance_name) %>% 
  filter(n() == 2) %>%   # results for both algorithms
  mutate(alg_config = if_else(str_detect(alg_config, "OSS"), "\\texttt{\\small OSS}", "\\texttt{\\small WLP}")) %>% 
  mutate(p = str_c("$p = ", p, "$")) 
p <- ggplot(dat, aes(x = n, y = cpuTotal, color = alg_config)) +
  geom_point(size = 0.5) +
  geom_smooth(se = F, size = 0.75) +
  facet_grid(cols = vars(class), rows = vars(p), scales = "free") + 
  xlab("Variable size ($n$)") + ylab("CPU (seconds)") +
  labs(color = "", linetype = "", alpha = "") +
  theme_publish() 
p

if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_oss.tex"), standAlone=F, width = 7, height = 4)
  print(p)
  dev.off()
}

dat1 <- dat %>%
  # group_by(instance_name) %>% 
  # filter(setequal(unique(configValSplit), rules)) %>%    # only instances with results for for all rules
  group_by(class, p, alg_config) %>%
  arrange(cpuTotal, .by_group = T) %>%
  mutate(count = row_number(), 
         total = n(), 
         pct = count/total) %>% 
  select(p, class, alg_config, cpuTotal, count, pct, total) %>% print()
  
p <- ggplot(dat1) +
  # geom_step(aes(x=tpstotal, y=count, color = nodeselVarsel, linetype = OB)) +
  geom_step(aes(y=pct, x=cpuTotal, color = alg_config), alpha = 0.75) +
  # geom_point(aes(y=..y.., x=cpuTotal, color = configLB, linetype = configValSplit), stat="ecdf", size = 0.5) +
  facet_grid(rows = vars(class), cols = vars(p)) +
  # ggtitle(str_c("Number of instances solved within a given CPU time")) +
  labs(color = "", linetype = "") +
  # scale_color_ob + #scale_linetype_nodesel_varsel +
  xlab("CPU (seconds)") + ylab("\\%") +
  theme_publish() +
  coord_cartesian(expand = FALSE, ylim = c(0, NA), xlim = c(-10, 3595)) 
p
if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_pref_oss.tex"), standAlone=F, width = 7, height = 6)
  print(p)
  dev.off()
}
```





## Pruneing 

```{r}
p <- datResult %>% 
  filter(solved == 1, configLB == "WLP", configValSplit %in% c("mofv", "binary")) %>%
  mutate(
    nbLeaf = nbFathomedInfeas + nbFathomedOptimality + nbFathomedDominance,
    pctFathomedInfeas = nbFathomedInfeas/nbLeaf,
    pctFathomedOptimality = nbFathomedOptimality/nbLeaf,
    pctFathomedDominance = nbFathomedDominance/nbLeaf
  ) %>%
  group_by(p, class) %>%
  summarise(across(starts_with("pct"), mean)) %>% 
  rename(infeasibility = pctFathomedInfeas, 
         optimality = pctFathomedOptimality, 
         dominance = pctFathomedDominance) %>% 
  pivot_longer(!c(class, p) , names_to = "part" , values_to = "pctCpu") %>%
  mutate(pctCpu = 100 * pctCpu) %>% 
  ggplot(aes(
    x = factor(class),
    y = pctCpu,
    fill = part
  )) +
  geom_col(color = "black") +
  geom_text(
    aes(label = round(pctCpu, 1)),
    colour = "white",
    size = 2.5,
    position = position_stack(vjust = .5)
  ) +
  facet_grid(
    cols = vars(p),
    # scales = "free"
  ) +
  labs(color = "", fill = "") +
  ylab("percent of leaf nodes") + xlab("") +
  theme_publish() 
p

if (copyTabFigs) {
  tikz(file = here(pathOverLeaf, "fig_leaf.tex"), standAlone=F, width = 7, height = 4)
  print(p)
  dev.off()
}
```
